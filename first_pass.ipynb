{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd43cdf",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create a working version of the HR agents. One supervisor agent will delegate tasks to the appropriate specialized agent. I will need to instantiate a number of objects to make everything run. I need both vector stores and a connection to the employee database. I also need to create the agents themselves using langgraph and langchain. Finally, I will need a state object to persist the message history and house personal information for the person interacting with the bot.\n",
    "\n",
    "Credit for the architecture goes to the langgraph documentation [here](https://langchain-ai.github.io/langgraph/tutorials/workflows/#routing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f15c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#connect to postgres db\n",
    "import psycopg\n",
    "#message templates, llm object, and vector store object\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "#manage state and create graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "#strictly define model input/output\n",
    "from pydantic import BaseModel, Field\n",
    "#include additional info for fields\n",
    "from typing import Annotated\n",
    "#only allow specific values for fields and explicit typing for dictionary\n",
    "from typing_extensions import Literal, TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0d08e",
   "metadata": {},
   "source": [
    "First, I need to instantiate a number of objects. I need objects to interact with each of my two vector stores. In order to create these, I need an instance of the embeddings object. I need an OpenAI chat model and a state dictionary for my message history / personal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04387d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to create embeddings from info and queries\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')  \n",
    "#url to locally hosted postgres db\n",
    "vector_connection = 'postgresql+psycopg://langchain:langchain@localhost:32768/henry'\n",
    "#collection names for two different vector collections\n",
    "benefits_collection = 'healthcare_plans'\n",
    "hr_collection = 'hr_policy'\n",
    "#benefits vector store\n",
    "benefits_vs = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=benefits_collection,\n",
    "    connection=vector_connection,\n",
    "    use_jsonb=True\n",
    ")\n",
    "#hr policy vector store\n",
    "hr_vs = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=hr_collection,\n",
    "    connection=vector_connection,\n",
    "    use_jsonb=True\n",
    ")\n",
    "#state object with explicit typing, will be populated by ai agents in workflow\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    agent: str\n",
    "    query: str\n",
    "    response: str\n",
    "    id: int\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    email: str\n",
    "    plan: str\n",
    "    is_manager: bool\n",
    "#model object\n",
    "llm = ChatOpenAI(model='gpt-5-nano')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41dc07",
   "metadata": {},
   "source": [
    "I have the ability to interact with both vector stores and a state object that will be updated as the program runs. Let's build a router that will send questions to one of our two agents: benefits specialist and HR policy expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b88bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explicit control over router output\n",
    "class Route(BaseModel):\n",
    "    agent: Literal['benefits', 'hr'] = Field(\n",
    "        None, description='Routes questions to the appropriate agent.'\n",
    "    )\n",
    "#router object to direct traffic within agentic workflow\n",
    "router = llm.with_structured_output(Route)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a69973",
   "metadata": {},
   "source": [
    "Great. Let's create a function to invoke our router with structured output. This will be the first node in the graph. The node will also contain a conditional check for user information. If it's not present, it will conduct a simple database query to collect the user information. The user information updates the state class that will be passed to all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb33d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#router node in workflow\n",
    "def llm_router(state: State):\n",
    "    '''Routes traffic to the appropriate agent.'''\n",
    "    #retrieve user's employee id (would be pulled automatically if part of webapp)\n",
    "    id = int(input('Enter your employee ID number: ').strip())\n",
    "    #establish connection to locally hosted database\n",
    "    connection = 'user=langchain password=langchain host=localhost port=32768 dbname=postgres'\n",
    "    with psycopg.connect(connection) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            #retrieve employee info and return the only row\n",
    "            cur.execute(f\"SELECT * FROM employees WHERE id = {id}\")\n",
    "            result = cur.fetchone()\n",
    "\n",
    "    #invoke the router model using the messages from the state\n",
    "    decision = router.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content='Route the query to the appropriate expert who can answer the question: HR policy expert or benefits specialist.'\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=state['query']\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    #the return statement updates the state object with employee info\n",
    "    return {\n",
    "        'agent': decision.agent,\n",
    "        'id': id,\n",
    "        'first_name': result[1],\n",
    "        'last_name': result[2],\n",
    "        'email': result[3],\n",
    "        'plan': result[4],\n",
    "        'is_manager': result[5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c82b3",
   "metadata": {},
   "source": [
    "Great. Now I need to define the two agents and create a decision function to route traffic to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ffcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hr policy node\n",
    "def hr_expert(state: State):\n",
    "    '''Answer questions related to HR policy.'''\n",
    "    #searches the hr policy vector store for 2 most relevant bits of information\n",
    "    result = hr_vs.similarity_search(\n",
    "        state['query'],\n",
    "        k=2\n",
    "    )\n",
    "    #extracts the page labels and content, formatting for prompt template invocation\n",
    "    context = {\n",
    "        'page1': result[0].metadata['page_label'] - 4,\n",
    "        'context1': result[0].page_content,\n",
    "        'page2': result[1].metadata['page_label'] - 4,\n",
    "        'context2': result[1].page_content,\n",
    "        'query': state['query']\n",
    "    }\n",
    "    #prompt template with placeholders matching keys in context dictionary\n",
    "    system_template = '''Answer the question regarding HR policy using the following context.\n",
    "                      Be sure to mention the page number(s) used to inform your answer.\n",
    "                      \n",
    "                      Page number: {page1}\n",
    "                      Context: {context1}\n",
    "                      \n",
    "                      Page number: {page2}\n",
    "                      Context: {context2}'''\n",
    "    #putting the system message with context together with user query\n",
    "    prompt_template = ChatPromptTemplate(\n",
    "        [('system', system_template), ('user', '{query}')]\n",
    "    )\n",
    "    #invokes prompt to inject context\n",
    "    prompt = prompt_template.invoke(context)\n",
    "    #gets response from llm and returns\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fa149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#benefits specialist node\n",
    "def benefits_specialist(state: State):\n",
    "    '''Answers questions regarding health care benefits.'''\n",
    "    print(state)\n",
    "    #gets 2 best matches from benefits vector store matching the user's plan\n",
    "    result = benefits_vs.similarity_search(\n",
    "        state['query'],\n",
    "        k=2,\n",
    "        filter={'subject': {'$eq': state['plan']}}\n",
    "    )\n",
    "    #extracts context and formats in dictionary\n",
    "    context = {\n",
    "        'page1': result[0].metadata['page_label'],\n",
    "        'context1': result[0].page_content,\n",
    "        'page2': result[1].metadata['page_label'],\n",
    "        'context2': result[1].page_content,\n",
    "        'query': state['query']\n",
    "    }\n",
    "    #defines template for system message with context\n",
    "    system_template = '''Answer the question regarding health benefits using the following context.\n",
    "                      Be sure to mention the page number(s) used to inform your answer.\n",
    "                      \n",
    "                      Page number: {page1}\n",
    "                      Context: {context1}\n",
    "                      \n",
    "                      Page number: {page2}\n",
    "                      Context: {context2}'''\n",
    "    #brings system prompt template together with user query\n",
    "    prompt_template = ChatPromptTemplate(\n",
    "        [('system', system_template), ('user', '{query}')]\n",
    "    )\n",
    "    #invokes prompt to populate prompts with context\n",
    "    prompt = prompt_template.invoke(context)\n",
    "    #gets llm response and returns\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#routes traffic based on specialist name returned from routing agent\n",
    "def route_decision(state: State):\n",
    "    '''Routes traffic to the appropriate agent.'''\n",
    "    if state['agent'] == 'hr':\n",
    "        return 'hr_expert'\n",
    "    elif state['agent'] == 'benefits':\n",
    "        return 'benefits_specialist'\n",
    "    else:\n",
    "        print('Not sure how we ended up here...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f0a88",
   "metadata": {},
   "source": [
    "Now I have all these elements created, I need to put them together in a graph and construct some edges between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd564e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates graph using state object\n",
    "router_builder = StateGraph(State)\n",
    "#adds my nodes: the router and the two specialists\n",
    "router_builder.add_node('llm_router', llm_router)\n",
    "router_builder.add_node('hr_expert', hr_expert)\n",
    "router_builder.add_node('benefits_specialist', benefits_specialist)\n",
    "#the start of the graph points to the router\n",
    "router_builder.add_edge(START, 'llm_router')\n",
    "#from the router, it makes a decision: send traffic to hr expert or benefits specialist\n",
    "router_builder.add_conditional_edges(\n",
    "    'llm_router',\n",
    "    route_decision,\n",
    "    {\n",
    "        'hr_expert': 'hr_expert',\n",
    "        'benefits_specialist': 'benefits_specialist'\n",
    "    }\n",
    ")\n",
    "#end the process after one of the specialists answers the question\n",
    "router_builder.add_edge('hr_expert', END)\n",
    "router_builder.add_edge('benefits_specialist', END)\n",
    "#compile the graph\n",
    "router_workflow = router_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34133d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [], 'agent': 'benefits', 'query': 'What is my copay for a mental health appointment?', 'id': 1, 'first_name': 'Adam', 'last_name': 'Krull', 'email': 'ak@company.ai', 'plan': 'Bronze', 'is_manager': False}\n",
      "Based on the document (page 3):\n",
      "\n",
      "- Outpatient mental health care: $50 copay for a PCP office visit or home visit, or 50% coinsurance after deductible for outpatient services, as applicable.\n",
      "- Inpatient mental health care: 50% coinsurance after deductible (not the question, but noted for completeness).\n",
      "\n",
      "So for a typical outpatient mental health appointment, you’d usually pay a $50 copay if it’s a PCP office visit or home visit; otherwise, you may pay 50% coinsurance after your deductible applies.\n"
     ]
    }
   ],
   "source": [
    "#testing my workflow - question was \"What should I expect to pay for mental health care?\"\n",
    "while True:\n",
    "    user_query = input('How can we help you? ').strip()\n",
    "    if user_query == 'stop':\n",
    "        break\n",
    "    else:\n",
    "        response = router_workflow.invoke({'query': user_query})\n",
    "        print(response['response'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cdb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
